================================================================
Repopack Output File
================================================================

This file was generated by Repopack on: 2024-10-22T10:41:34.605Z

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This header section
2. Repository structure
3. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
1. This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
2. When processing this file, use the separators and "File:" markers to
  distinguish between different files in the repository.
3. Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.



For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
.gitignore
Dockerfile
index.js
package.json
scrapeLogic.js

================================================================
Repository Files
================================================================

================
File: .gitignore
================
node_modules

================
File: Dockerfile
================
FROM ghcr.io/puppeteer/puppeteer:23.6.0
ENV  PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true \
     PUPPETEER_EXECUTABLE_PATH=/usr/bin/google-chrome-stable

WORKDIR /usr/src/app

COPY package*.json ./
RUN npm ci
COPY . .
CMD ["node","index.js"]

================
File: index.js
================
const express = require ("express");
const {scrapeLogic} = require ('./scrapeLogic')
const app = express();

const PORT = process.env.PORT || 4000;

app.get("/",(req,res) =>{
    res.send("El server funciona")
});

app.get("/scrape",(req,res) =>{
    scrapeLogic(res);
} );

app.listen(PORT,() => {
console.log(`Servidor inicializado en el puerto ${PORT}`)
});

================
File: package.json
================
{
  "name": "prueba-puppeteer",
  "version": "1.0.0",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1",
    "start": "node index"
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "description": "",
  "dependencies": {
    "chromium": "^3.0.3",
    "dotenv": "^16.4.5",
    "express": "^4.21.1",
    "puppeteer": "^23.6.0"
  }
}

================
File: scrapeLogic.js
================
const puppeteer = require("puppeteer")
require("dotenv").config;

const scrapeLogic = async (res) => {
    const browser = await puppeteer.launch({
        args:[
            "--disable-setuid-sandbox",
            "--no-sandbox",
            "--single-process",
            "--no-zygote",
        ],
        executablePath: process.env.NODE_ENV ==='production'
        ? process.env.PUPPETEER_EXECUTABLE_PATH
        : puppeteer.executablePath,
    });
    try {
        const page = await browser.newPage();

        // Navigate the page to a URL.
        await page.goto('https://developer.chrome.com/');

        // Set screen size.
        await page.setViewport({ width: 1080, height: 1024 });

        // Type into search box.
        await page.locator('.devsite-search-field').fill('automate beyond recorder');

        // Wait and click on first result.
        await page.locator('.devsite-result-item-link').click();

        // Locate the full title with a unique string.
        const textSelector = await page
            .locator('text/Customize and automate')
            .waitHandle();
        const fullTitle = await textSelector?.evaluate(el => el.textContent);

        // Print the full title.
        const logStatement = `El titulo del ultimo artículo es: ${fullTitle}`
        console.log(logStatement);
        res.send(logStatement);
    }
    catch (e) {
        console.error(e);
        res.send(`Algo salió mal ${e}`)
    } finally {
        await browser.close();
    }
};


module.exports = { scrapeLogic };
